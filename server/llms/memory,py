import time
import os
from qdrant_client import QdrantClient
from qdrant_client.models import VectorParams, Distance
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

# ------------ Qdrant Setup ------------
QDRANT_URL = os.getenv("QDRANT_URL")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")

client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)
collection = "episodic_memory"

client.recreate_collection(
    collection_name=collection,
    vectors_config=VectorParams(size=1536, distance=Distance.COSINE)
)

# Embeddings + LLM
embedding_model = OpenAIEmbeddings(model="text-embedding-3-large")
summary_llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.2)


# ------------ Summarizer ------------
def create_episode(raw_history: str):
    """
    Takes raw chat history text.
    Returns episodic summary + importance.
    """

    prompt = f"""
Turn the following chat transcript into an episodic memory summary.

Return JSON with:
- story: short natural-language summary (1â€“2 sentences)
- importance: number between 0 and 1 (how personally meaningful this is)

Transcript:
{raw_history}

JSON:
"""

    out = summary_llm.invoke(prompt).content
    return eval(out)  # Since LLM returns safe JSON in eval-safe format


# ------------ Store in Qdrant ------------
def store_episode(story: str, importance: float):
    vector = embedding_model.embed_query(story)

    client.upsert(
        collection_name=collection,
        points=[{
            "id": int(time.time() * 1000),
            "vector": vector,
            "payload": {
                "story": story,
                "importance": importance,
                "timestamp": time.time()
            }
        }]
    )

    return True


# ------------ Main pipeline ------------
def save_memory(raw_history: str):
    episode = create_episode(raw_history)

    story = episode["story"]
    importance = float(episode["importance"])

    store_episode(story, importance)

    return {
        "status": "stored",
        "story": story,
        "importance": importance
    }
